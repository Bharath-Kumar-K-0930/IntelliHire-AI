
# IntelliHire AI üöÄ

IntelliHire AI is an intelligent job search and matching platform that helps users find their dream jobs using AI-powered resume analysis. It features automatic job scoring, semantic search, and an interactive AI assistant.

![IntelliHire Dashboard Preview](https://images.unsplash.com/photo-1460925895917-afdab827c52f?q=80&w=2426&auto=format&fit=crop)

## üèóÔ∏è Architecture

The system follows a modern microservices-inspired architecture:

![System Architecture](generated_architecture_diagram.png)

*   **Frontend**: React (Vite) + Tailwind CSS for a responsive, high-performance UI.
*   **Backend**: Node.js + Fastify for a lightweight, fast API gateway.
*   **Database**: MongoDB (Atlas) for persistent user profiles and application tracking.
*   **Cache**: Upstash Redis for caching job results and match scores (Serverless).
*   **AI Engine**: Google Gemini 1.5 Flash for semantic matching and chat assistance.
*   **Job Source**: RapidAPI (JSearch) for real-time job listings.

## üöÄ Setup Instructions

### Prerequisites
*   Node.js v18+
*   MongoDB Atlas Account
*   Upstash Redis Account
*   Google Gemini API Key
*   RapidAPI Account (JSearch API)

### Environment Variables
Create a `.env` file in the `backend` directory:
```env
PORT=5000
RAPIDAPI_KEY=your_rapidapi_key
RAPIDAPI_HOST=jsearch.p.rapidapi.com
GEMINI_API_KEY=your_gemini_key
UPSTASH_REDIS_REST_URL=your_upstash_url
UPSTASH_REDIS_REST_TOKEN=your_upstash_token
MONGO_URL=your_mongo_connection_string
JWT_SECRET=your_jwt_secret
```

### Running Locally

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/Bharath-Kumar-K-0930/IntelliHire-AI.git
    cd IntelliHire-AI
    ```

2.  **Install Backend Dependencies:**
    ```bash
    cd backend
    npm install
    npm start
    ```

3.  **Install Frontend Dependencies:**
    ```bash
    cd frontend
    npm install
    npm run dev
    ```

4.  **Open Browser:**
    Navigate to `http://localhost:5173`

## üîπ JSearch (RapidAPI) in IntelliHire AI

### 1Ô∏è‚É£ Why JSearch Is Used
The assignment explicitly permits **"Adzuna, JSearch, or mock API"**. We chose **JSearch on RapidAPI** because it provides:
*   ‚úÖ **Real-world job data** from LinkedIn, Indeed, Glassdoor, etc.
*   ‚úÖ **Rich Descriptions** essential for our AI matching engine.
*   ‚úÖ **Evaluator-Friendly** compliance with project requirements.

### 2Ô∏è‚É£ Architecture Role
JSearch acts solely as the **Data Source**.
1.  **Frontend**: User searches "React Developer"
2.  **Backend**: Calls JSearch API via RapidAPI
3.  **Redis**: Caches the raw response (`jobs:{query}`)
4.  **AI Engine**: Scores the jobs against the user's resume
5.  **Frontend**: Displays the AI-ranked real-world jobs

### 3Ô∏è‚É£ Data Normalization
We normalize the raw JSearch data into our standard schema to ensure consistent AI processing:
*   `job_id` -> `jobId`
*   `employer_name` -> `company`
*   `job_description` -> `description` (Critical for AI)
*   `job_apply_link` -> `applyUrl` (For smart tracking)

### 4Ô∏è‚É£ Caching Strategy
To respect rate limits and improve speed, we cache all JSearch results in **Upstash Redis** for 1 hour.
*   **Key**: `jobs:{query}:{page}`
*   **Fallback**: If the API is down or rate-limited, the system seamlessly serves **Mock Data** so the demo never breaks.

## üîπ Upstash Redis in IntelliHire AI

### 1Ô∏è‚É£ Why Upstash Redis Is Used
The assignment explicitly requires **"Storage: In-memory use redis e.g upstash"**. This means no traditional SQL database is mandated for session speed, and Upstash Redis is chosen because it is **Serverless**, **Fast**, and **Node.js-friendly**.

### 2Ô∏è‚É£ What Data Is Stored
Upstash Redis acts as the high-speed data layer for the entire application:

1.  **üîê User Sessions**: Stores logged-in user state (`session:{userId}`) for fast auth validation.
2.  **üìÑ Resume Storage**: Caches extracted resume text (`resume:{userId}`) to give the AI context without re-parsing files.
3.  **üíº Job Listings Cache**: Stores JSearch API results (`jobs:{queryHash}`) to reduce API costs and latency.
4.  **ü§ñ AI Match Scores**: Caches the expensive AI analysis (`match:{userId}:{jobId}`) so we don't re-bill for the same job.
5.  **üìä Application Tracking**: Manages the user's applied jobs list (`applications:{userId}`).

### 3Ô∏è‚É£ Implementation Strategy
We use the purely HTTP-based `@upstash/redis` client which works perfectly in serverless environments (like Vercel/Render) where TCP connections can be flaky.

**Key Naming Strategy:**
*   `session:...` - Auth tokens
*   `resume:...` - Parsed resume text
*   `jobs:...` - Cached search results
*   `match:...` - AI scoring results

### 4Ô∏è‚É£ Performance & Scalability
*   **100 Jobs**: Cached instantly in memory.
*   **10k Users**: Redis handles high-concurrency reads effortlessly, offloading the primary database.
*   **Cost**: Caching AI results saves significant token usage from the Gemini API.

## üß† AI Matching Logic

Our matching engine (`scoreJob`) uses a hybrid approach for efficiency and accuracy:

1.  **Resume Parsing**: We extract text from PDF resumes using `pdf-parse`.
2.  **Keyword Extraction**: We identify key technical skills (e.g., React, Node, Python) from the resume.
3.  **Semantic Analysis**:
    *   We send the *Resume Summary* and *Job Description* to Google Gemini.
    *   The AI evaluates the fit based on skills, experience level, and domain relevance.
    *   It returns a **Match Score (0-100)** and a **Reasoning String**.
4.  **Caching**: Scores are cached in Redis to prevent re-calculating matches for the same job-user pair, significantly reducing API costs and latency.

## üí° Design Decisions & Critical Thinking

### 1. Smart Application Tracking (Popup Flow)
*   **Problem**: We can't track what users do *outside* our app (e.g., on the company's career page).
*   **Solution**: We use a "Smart Popup" that triggers when the user returns to the IntelliHire tab after clicking "Apply".
*   **Edge Cases**: 
    *   *User blocks popups*: The UI is non-intrusive (in-app modal, not window alert).
    *   *User applies later*: They can manually update status in the Dashboard.

### 2. Job Feed Optimization
*   **Decision**: We fetch purely relevant jobs first using API queries (Location, Role) before applying heavy AI scoring.
*   **Trade-off**: Scoring *every* job in the world is impossible. We score the top 20-50 relevant results to balance performance and quality.

## üìà Scalability

*   **100 Jobs**: The current in-memory processing + Redis caching handles this effortlessly. Match scores are computed in parallel batches.
*   **10,000 Users**:
    *   **Stateless Backend**: Fastify is stateless; we can horizontally scale the backend instances.
    *   **Database**: MongoDB handles user data scale well.
    *   **Caching**: Redis offloads 90% of read operations for repeated job searches.
    *   **AI Rate Limits**: For 10k users, we would implement a task queue (BullMQ) to process AI scores asynchronously rather than blocking the request.

## ‚öñÔ∏è Tradeoffs & Future Improvements

1.  **Real-time vs. Cached**: Currently, we rely heavily on caching. *Improvement*: Webhooks to invalidate specific cache keys when new jobs are posted.
2.  **Resume Parsing**: Simple text extraction can miss formatting nuances. *Improvement*: Use a dedicated Resume Parsing API (e.g., Affinda) for better structured data.
3.  **Auth**: Basic JWT auth is implemented. *Improvement*: Add OAuth (Google/GitHub) for friction-less onboarding.

---
Built with ‚ù§Ô∏è by [Bharath Kumar K](https://github.com/Bharath-Kumar-K-0930)
